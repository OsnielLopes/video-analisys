{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Projeto da disciplina de Computação Visual - 7N - 1ºSem/2019\n",
    "\n",
    "Como usar:\n",
    "1. Alterar as variaveis na segunda célula: **input_video_path** e **output_video_path**, que indicam, respectivamente, o video de entrada e o video de saida.\n",
    "2. Executar todas as células.\n",
    "\n",
    "Os videos de exemplo se encontram na pasta output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports nescessarios para execução do algoritmo\n",
    "\n",
    "import numpy as np\n",
    "import imutils\n",
    "import time\n",
    "# módulo de visão computacional\n",
    "import cv2\n",
    "# módulo que que se comunica com o sistema operacional\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Caminhos para o video de entrada, saida e local do dataset\n",
    "input_video_path = \"videos/mackenzie.MOV\"\n",
    "output_video_path = \"output/mackenzie.avi\"\n",
    "yolo_path = \"yolo-coco\"\n",
    "\n",
    "# Probabilidade mínima para filtrar detecções fracas\n",
    "confidence = 0.5\n",
    "# Limite ao aplicar a supressão não máxima\n",
    "threshold = 0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carrega as legendas das classes COCO com o qual o modelo foi treinado\n",
    "labelsPath = os.path.sep.join([yolo_path, \"coco.names\"])\n",
    "LABELS = open(labelsPath).read().strip().split(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inicializa um lista de cores para representar as classes\n",
    "np.random.seed(42)\n",
    "COLORS = np.random.randint(0, 255, size=(len(LABELS), 3), dtype=\"uint8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# leitura do tamanho e da configuração do modelo\n",
    "weightsPath = os.path.sep.join([yolo_path, \"yolov3.weights\"])\n",
    "configPath = os.path.sep.join([yolo_path, \"yolov3.cfg\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Carregando treinamento do disco...\n"
     ]
    }
   ],
   "source": [
    "print(\"[INFO] Carregando treinamento do disco...\")\n",
    "# leitura do CV2 dos modelos\n",
    "net = cv2.dnn.readNetFromDarknet(configPath, weightsPath)\n",
    "# Define o nome das camadas\n",
    "ln = net.getLayerNames()\n",
    "ln = [ln[i[0] - 1] for i in net.getUnconnectedOutLayers()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Captura do video selecionado\n",
    "vs = cv2.VideoCapture(input_video_path)\n",
    "writer = None\n",
    "(W, H) = (None, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] 353 Total de frames no video\n"
     ]
    }
   ],
   "source": [
    "# Determina a quantidade de frames total que o video tem\n",
    "try:\n",
    "    prop = cv2.cv.CV_CAP_PROP_FRAME_COUNT if imutils.is_cv2() \\\n",
    "        else cv2.CAP_PROP_FRAME_COUNT\n",
    "    total = int(vs.get(prop))\n",
    "    print(\"[INFO] {} Total de frames no video\".format(total))\n",
    "    \n",
    "# Tratamento em caso de ERRO\n",
    "except:\n",
    "    print(\"[INFO] Não é possivel determinar a quantidade de frames para este video\")\n",
    "    total = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] um frame levou 1.0965 sgundos\n",
      "[INFO] Tempo total estimado: 387.0740\n",
      "[INFO] Finalizando...\n"
     ]
    }
   ],
   "source": [
    "# loop para cada frame do video\n",
    "while True:\n",
    "    # Leitura do proximo frame\n",
    "    (grabbed, frame) = vs.read()\n",
    "\n",
    "    # Se o grabbed estiver vazio, terminar execução\n",
    "    if not grabbed:\n",
    "        break\n",
    "\n",
    "    # Se a dimensão estiver vazia, ela será prenchida\n",
    "    if W is None or H is None:\n",
    "        (H, W) = frame.shape[:2]\n",
    "\n",
    "    # Constroe a variavel blob a partir do frame\n",
    "    blob = cv2.dnn.blobFromImage(frame, 1 / 255.0, (416, 416),\n",
    "        swapRB=True, crop=False)\n",
    "    # Passa os dados pela rede\n",
    "    net.setInput(blob)\n",
    "    start = time.time()\n",
    "    layerOutputs = net.forward(ln)\n",
    "    end = time.time()\n",
    "\n",
    "    # Inicializa as listas nescessarias\n",
    "    boxes = []\n",
    "    confidences = []\n",
    "    classIDs = []\n",
    "\n",
    "    # Loop para cada saida de layer\n",
    "    for output in layerOutputs:\n",
    "        # Loop para cada detecção\n",
    "        for detection in output:\n",
    "            # Extrai a classID e confianca da deteccao\n",
    "            scores = detection[5:]\n",
    "            classID = np.argmax(scores)\n",
    "            aconfidence = scores[classID]\n",
    "\n",
    "            # Filtrar previsões fracas, garantindo que a probabilidade detectada seja maior que a probabilidade mínima\n",
    "            if aconfidence > confidence:\n",
    "                # Recebe as cordenadas para definir o tamanho do box\n",
    "                box = detection[0:4] * np.array([W, H, W, H])\n",
    "                (centerX, centerY, width, height) = box.astype(\"int\")\n",
    "\n",
    "                # Usa coordenadas do centro para derivar topo e largura\n",
    "                x = int(centerX - (width / 2))\n",
    "                y = int(centerY - (height / 2))\n",
    "\n",
    "                # Atualiza listas\n",
    "                boxes.append([x, y, int(width), int(height)])\n",
    "                confidences.append(float(aconfidence))\n",
    "                classIDs.append(classID)\n",
    "\n",
    "    # Aplicar supressão não máxima para suprimir caixas delimitadoras fracas e sobrepostas\n",
    "    idxs = cv2.dnn.NMSBoxes(boxes, confidences, confidence, threshold)\n",
    "\n",
    "    # Garante que existe pelo menos uma detecção\n",
    "    if len(idxs) > 0:\n",
    "        # Loop sobre os índices que estamos mantendo\n",
    "        for i in idxs.flatten():\n",
    "            # Extrai as coordenadas do box\n",
    "            (x, y) = (boxes[i][0], boxes[i][1])\n",
    "            (w, h) = (boxes[i][2], boxes[i][3])\n",
    "\n",
    "            # Desenha o quadrado para o modelo\n",
    "            color = [int(c) for c in COLORS[classIDs[i]]]\n",
    "            cv2.rectangle(frame, (x, y), (x + w, y + h), color, 2)\n",
    "            text = \"{}: {:.4f}\".format(LABELS[classIDs[i]],\n",
    "            confidences[i])\n",
    "            cv2.putText(frame, text, (x, y - 5),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)\n",
    "\n",
    "    # Valida se o video escrito está vazio\n",
    "    if writer is None:\n",
    "        # Inicializa a escrita do video\n",
    "        fourcc = cv2.VideoWriter_fourcc(*\"MJPG\")\n",
    "        writer = cv2.VideoWriter(output_video_path, fourcc, 30,\n",
    "            (frame.shape[1], frame.shape[0]), True)\n",
    "\n",
    "        if total > 0:\n",
    "            elap = (end - start)\n",
    "            print(\"[INFO] um frame levou {:.4f} sgundos\".format(elap))\n",
    "            print(\"[INFO] Tempo total estimado: {:.4f}\".format(elap * total))\n",
    "\n",
    "    # Escreve o video no disco local\n",
    "    writer.write(frame)\n",
    "\n",
    "# Libera os ponteiros de arquivos\n",
    "print(\"[INFO] Finalizando...\")\n",
    "writer.release()\n",
    "vs.release()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
